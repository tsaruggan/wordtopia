{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b2ae0a-c526-4e2b-911b-0462d35954b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538969dc-c62d-4cf9-a1bd-433d84c08dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = pq.ParquetFile(\"../data.parquet\")\n",
    "conn = sqlite3.connect(\"dictionary.db\")\n",
    "for batch in pf.iter_batches(batch_size=100):\n",
    "    df = batch.to_pandas()\n",
    "    df[[\"word\", \"definition\"]].to_sql(\"dictionary\", conn, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3130ffec-b747-43b2-a7df-bbbeba76064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordNotFoundException(Exception):\n",
    "    def __init__(self, word):\n",
    "        self.message = f\"The word '{word}' does not exist in the dictionary.\"\n",
    "        super().__init__(self.message)\n",
    "\n",
    "class DatabaseFailureException(Exception):\n",
    "    def __init__(self, error_message):\n",
    "        self.message = f\"Database failure: {error_message}\"\n",
    "        super().__init__(self.message)\n",
    "\n",
    "class Database:\n",
    "    def __init__(self, database_name):\n",
    "        self.db = sqlite3.connect(database_name)\n",
    "        self.db.row_factory = sqlite3.Row\n",
    "        \n",
    "    def populate(self, dataset_name):\n",
    "        pf = pq.ParquetFile(dataset_name)\n",
    "        current_id = 0\n",
    "        for batch in pf.iter_batches(batch_size=1000):\n",
    "            df = batch.to_pandas()\n",
    "            df = df[[\"word\", \"definition\"]]\n",
    "            df.insert(0, \"id\", range(current_id, current_id + len(df)))\n",
    "            df.to_sql(\"dictionary\", self.db, if_exists=\"append\", index=False)\n",
    "            current_id += len(df)\n",
    "\n",
    "    def word_exists(self, word):\n",
    "        try:\n",
    "            query = \"SELECT 1 FROM dictionary WHERE word = ? LIMIT 1\"\n",
    "            cursor = self.db.execute(query, (word,))\n",
    "            exists = cursor.fetchone() is not None\n",
    "            return exists\n",
    "        except Exception as e:\n",
    "            raise DatabaseFailureException(str(e))\n",
    "\n",
    "    def get_id(self, word):\n",
    "        if not self.word_exists(word):\n",
    "            raise WordNotFoundException(word)\n",
    "\n",
    "        try:\n",
    "            query = \"SELECT id FROM dictionary WHERE word = ?\"\n",
    "            cursor = self.db.execute(query, (word,))\n",
    "            result = cursor.fetchone()\n",
    "            word_id = result[\"id\"]\n",
    "            return word_id\n",
    "        except Exception as e:\n",
    "            raise DatabaseFailureException(str(e))\n",
    "\n",
    "    def get_dictionary_records(self, ids):\n",
    "        try:\n",
    "            placeholder = \",\".join(\"?\" for _ in ids)\n",
    "            query = f\"SELECT id, word, definition FROM dictionary WHERE id IN ({placeholder})\"\n",
    "            cursor = self.db.execute(query, ids)\n",
    "            result = cursor.fetchall()\n",
    "            records = [dict(row) for row in result]\n",
    "            dictionary_records = {item[\"id\"]: item for item in records}\n",
    "            return dictionary_records\n",
    "        except Exception as e:\n",
    "            raise DatabaseFailureException(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9976d9ff-66b4-492d-8770-b6af8bf4f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Database(\"dictionary.db\")\n",
    "db.populate(\"./data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c12ce624-4748-432b-938e-fac4f1d1b9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: {'id': 4,\n",
       "  'word': 'abalone',\n",
       "  'definition': 'A type of marine mollusk known for its shell.'},\n",
       " 1000: {'id': 1000,\n",
       "  'word': 'ancient',\n",
       "  'definition': 'Belonging to the very distant past.'},\n",
       " 2024: {'id': 2024,\n",
       "  'word': 'barbel',\n",
       "  'definition': 'A type of fish with elongated whiskers.'}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = Database(\"dictionary.db\")\n",
    "db.get_dictionary_records([4, 1000, 2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce1eb138-8070-4f12-abb6-97cd8a2d72d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnswlib\n",
    "import numpy as np\n",
    "\n",
    "class VectorSearch:\n",
    "    def __init__(self, index_name, embedding_size, word_count, M=16, ef_construction=200, ef=256):\n",
    "        self.index_name = index_name\n",
    "        self.embedding_size = embedding_size\n",
    "        self.word_count = word_count\n",
    "        self.M = M\n",
    "        self.ef_construction = ef_construction\n",
    "        self.ef = ef\n",
    "\n",
    "        self.index = hnswlib.Index(space = 'cosine', dim = embedding_size)\n",
    "        self.index.init_index(max_elements = word_count, ef_construction=ef_construction, M=M)\n",
    "        self.index.set_ef(ef)\n",
    "\n",
    "    def load(self):\n",
    "        self.index.load_index(self.index_name, max_elements = self.word_count)\n",
    "        self.index.set_ef(self.ef)\n",
    "\n",
    "    def populate(self, dataset_name):\n",
    "        pf = pq.ParquetFile(dataset_name)\n",
    "        current_id = 0\n",
    "        for batch in pf.iter_batches(batch_size=1000):\n",
    "            df = batch.to_pandas()\n",
    "            embeddings = np.stack(df[\"embedding\"].to_numpy())\n",
    "            self.index.add_items(embeddings, range(current_id, current_id + len(df)))\n",
    "            current_id += len(df)\n",
    "        self.index.save_index(self.index_name)\n",
    "\n",
    "    def search(self, word_id, top_n):\n",
    "        embedding = self.index.get_items([word_id])[0]\n",
    "        labels, distances = self.index.knn_query([embedding], k=top_n + 1)\n",
    "\n",
    "        index_records = {}\n",
    "        for label, distance in zip(labels[0], distances[0]):\n",
    "            similarity = 1.0 if label == word_id else 1.0 - distance\n",
    "            index_records[label] = {\"id\": label, \"similarity\": similarity}\n",
    "        return index_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "529d4298-119a-4412-8ecc-70a4bf984f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_search = VectorSearch('index.bin', 1536, 28032)\n",
    "vector_search.populate(\"./data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0bcb129-2906-4881-9506-af26ec11ff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Calling load_index for an already inited index. Old index is being deallocated.\n"
     ]
    }
   ],
   "source": [
    "vector_search = VectorSearch('index.bin', 1536, 28032)\n",
    "vector_search.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f4ac8a6-b1a8-48ff-8860-afa702ce8a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: {'id': 4, 'similarity': 1.0},\n",
       " 17708: {'id': 17708, 'similarity': 0.5715104341506958},\n",
       " 8552: {'id': 8552, 'similarity': 0.5369500517845154},\n",
       " 22041: {'id': 22041, 'similarity': 0.5336644649505615},\n",
       " 4349: {'id': 4349, 'similarity': 0.5271939039230347},\n",
       " 1120: {'id': 1120, 'similarity': 0.5264646410942078},\n",
       " 14653: {'id': 14653, 'similarity': 0.5210265517234802},\n",
       " 770: {'id': 770, 'similarity': 0.5058796405792236},\n",
       " 22661: {'id': 22661, 'similarity': 0.49759751558303833},\n",
       " 22777: {'id': 22777, 'similarity': 0.48571449518203735}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_search.search(4, 8+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f14e9a-ef18-4aec-ae9e-6659b077c5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
